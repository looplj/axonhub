// Code generated by ent, DO NOT EDIT.

package ent

import (
	"context"
	"database/sql/driver"
	"fmt"

	"entgo.io/contrib/entgql"
	"entgo.io/ent/dialect/sql"
	"github.com/99designs/gqlgen/graphql"
	"github.com/looplj/axonhub/internal/ent/apikey"
	"github.com/looplj/axonhub/internal/ent/channel"
	"github.com/looplj/axonhub/internal/ent/job"
	"github.com/looplj/axonhub/internal/ent/request"
	"github.com/looplj/axonhub/internal/ent/requestexecution"
	"github.com/looplj/axonhub/internal/ent/role"
	"github.com/looplj/axonhub/internal/ent/system"
	"github.com/looplj/axonhub/internal/ent/usagelog"
	"github.com/looplj/axonhub/internal/ent/user"
)

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (akq *APIKeyQuery) CollectFields(ctx context.Context, satisfies ...string) (*APIKeyQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return akq, nil
	}
	if err := akq.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return akq, nil
}

func (akq *APIKeyQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(apikey.Columns))
		selectedFields = []string{apikey.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: akq.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			akq.withUser = query
			if _, ok := fieldSeen[apikey.FieldUserID]; !ok {
				selectedFields = append(selectedFields, apikey.FieldUserID)
				fieldSeen[apikey.FieldUserID] = struct{}{}
			}

		case "requests":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: akq.config}).Query()
			)
			args := newRequestPaginateArgs(fieldArgs(ctx, new(RequestWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					akq.loadTotal = append(akq.loadTotal, func(ctx context.Context, nodes []*APIKey) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"api_key_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(apikey.RequestsColumn), ids...))
						})
						if err := query.GroupBy(apikey.RequestsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					akq.loadTotal = append(akq.loadTotal, func(_ context.Context, nodes []*APIKey) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Requests)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(apikey.RequestsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			akq.WithNamedRequests(alias, func(wq *RequestQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[apikey.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, apikey.FieldCreatedAt)
				fieldSeen[apikey.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[apikey.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, apikey.FieldUpdatedAt)
				fieldSeen[apikey.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[apikey.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, apikey.FieldDeletedAt)
				fieldSeen[apikey.FieldDeletedAt] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[apikey.FieldUserID]; !ok {
				selectedFields = append(selectedFields, apikey.FieldUserID)
				fieldSeen[apikey.FieldUserID] = struct{}{}
			}
		case "key":
			if _, ok := fieldSeen[apikey.FieldKey]; !ok {
				selectedFields = append(selectedFields, apikey.FieldKey)
				fieldSeen[apikey.FieldKey] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[apikey.FieldName]; !ok {
				selectedFields = append(selectedFields, apikey.FieldName)
				fieldSeen[apikey.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[apikey.FieldStatus]; !ok {
				selectedFields = append(selectedFields, apikey.FieldStatus)
				fieldSeen[apikey.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		akq.Select(selectedFields...)
	}
	return nil
}

type apikeyPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []APIKeyPaginateOption
}

func newAPIKeyPaginateArgs(rv map[string]any) *apikeyPaginateArgs {
	args := &apikeyPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &APIKeyOrder{Field: &APIKeyOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithAPIKeyOrder(order))
			}
		case *APIKeyOrder:
			if v != nil {
				args.opts = append(args.opts, WithAPIKeyOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*APIKeyWhereInput); ok {
		args.opts = append(args.opts, WithAPIKeyFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (cq *ChannelQuery) CollectFields(ctx context.Context, satisfies ...string) (*ChannelQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return cq, nil
	}
	if err := cq.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return cq, nil
}

func (cq *ChannelQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(channel.Columns))
		selectedFields = []string{channel.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "requests":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: cq.config}).Query()
			)
			args := newRequestPaginateArgs(fieldArgs(ctx, new(RequestWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					cq.loadTotal = append(cq.loadTotal, func(ctx context.Context, nodes []*Channel) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"channel_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(channel.RequestsColumn), ids...))
						})
						if err := query.GroupBy(channel.RequestsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					cq.loadTotal = append(cq.loadTotal, func(_ context.Context, nodes []*Channel) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Requests)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(channel.RequestsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			cq.WithNamedRequests(alias, func(wq *RequestQuery) {
				*wq = *query
			})

		case "executions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestExecutionClient{config: cq.config}).Query()
			)
			args := newRequestExecutionPaginateArgs(fieldArgs(ctx, new(RequestExecutionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestExecutionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					cq.loadTotal = append(cq.loadTotal, func(ctx context.Context, nodes []*Channel) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"channel_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(channel.ExecutionsColumn), ids...))
						})
						if err := query.GroupBy(channel.ExecutionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					cq.loadTotal = append(cq.loadTotal, func(_ context.Context, nodes []*Channel) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Executions)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestexecutionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(channel.ExecutionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			cq.WithNamedExecutions(alias, func(wq *RequestExecutionQuery) {
				*wq = *query
			})

		case "usageLogs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UsageLogClient{config: cq.config}).Query()
			)
			args := newUsageLogPaginateArgs(fieldArgs(ctx, new(UsageLogWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUsageLogPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					cq.loadTotal = append(cq.loadTotal, func(ctx context.Context, nodes []*Channel) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"channel_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(channel.UsageLogsColumn), ids...))
						})
						if err := query.GroupBy(channel.UsageLogsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					cq.loadTotal = append(cq.loadTotal, func(_ context.Context, nodes []*Channel) error {
						for i := range nodes {
							n := len(nodes[i].Edges.UsageLogs)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, usagelogImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(channel.UsageLogsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			cq.WithNamedUsageLogs(alias, func(wq *UsageLogQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[channel.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, channel.FieldCreatedAt)
				fieldSeen[channel.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[channel.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, channel.FieldUpdatedAt)
				fieldSeen[channel.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[channel.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, channel.FieldDeletedAt)
				fieldSeen[channel.FieldDeletedAt] = struct{}{}
			}
		case "type":
			if _, ok := fieldSeen[channel.FieldType]; !ok {
				selectedFields = append(selectedFields, channel.FieldType)
				fieldSeen[channel.FieldType] = struct{}{}
			}
		case "baseURL":
			if _, ok := fieldSeen[channel.FieldBaseURL]; !ok {
				selectedFields = append(selectedFields, channel.FieldBaseURL)
				fieldSeen[channel.FieldBaseURL] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[channel.FieldName]; !ok {
				selectedFields = append(selectedFields, channel.FieldName)
				fieldSeen[channel.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[channel.FieldStatus]; !ok {
				selectedFields = append(selectedFields, channel.FieldStatus)
				fieldSeen[channel.FieldStatus] = struct{}{}
			}
		case "supportedModels":
			if _, ok := fieldSeen[channel.FieldSupportedModels]; !ok {
				selectedFields = append(selectedFields, channel.FieldSupportedModels)
				fieldSeen[channel.FieldSupportedModels] = struct{}{}
			}
		case "defaultTestModel":
			if _, ok := fieldSeen[channel.FieldDefaultTestModel]; !ok {
				selectedFields = append(selectedFields, channel.FieldDefaultTestModel)
				fieldSeen[channel.FieldDefaultTestModel] = struct{}{}
			}
		case "settings":
			if _, ok := fieldSeen[channel.FieldSettings]; !ok {
				selectedFields = append(selectedFields, channel.FieldSettings)
				fieldSeen[channel.FieldSettings] = struct{}{}
			}
		case "orderingWeight":
			if _, ok := fieldSeen[channel.FieldOrderingWeight]; !ok {
				selectedFields = append(selectedFields, channel.FieldOrderingWeight)
				fieldSeen[channel.FieldOrderingWeight] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		cq.Select(selectedFields...)
	}
	return nil
}

type channelPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ChannelPaginateOption
}

func newChannelPaginateArgs(rv map[string]any) *channelPaginateArgs {
	args := &channelPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ChannelOrder{Field: &ChannelOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithChannelOrder(order))
			}
		case *ChannelOrder:
			if v != nil {
				args.opts = append(args.opts, WithChannelOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ChannelWhereInput); ok {
		args.opts = append(args.opts, WithChannelFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (jq *JobQuery) CollectFields(ctx context.Context, satisfies ...string) (*JobQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return jq, nil
	}
	if err := jq.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return jq, nil
}

func (jq *JobQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(job.Columns))
		selectedFields = []string{job.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "ownerID":
			if _, ok := fieldSeen[job.FieldOwnerID]; !ok {
				selectedFields = append(selectedFields, job.FieldOwnerID)
				fieldSeen[job.FieldOwnerID] = struct{}{}
			}
		case "type":
			if _, ok := fieldSeen[job.FieldType]; !ok {
				selectedFields = append(selectedFields, job.FieldType)
				fieldSeen[job.FieldType] = struct{}{}
			}
		case "context":
			if _, ok := fieldSeen[job.FieldContext]; !ok {
				selectedFields = append(selectedFields, job.FieldContext)
				fieldSeen[job.FieldContext] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		jq.Select(selectedFields...)
	}
	return nil
}

type jobPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []JobPaginateOption
}

func newJobPaginateArgs(rv map[string]any) *jobPaginateArgs {
	args := &jobPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[whereField].(*JobWhereInput); ok {
		args.opts = append(args.opts, WithJobFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (rq *RequestQuery) CollectFields(ctx context.Context, satisfies ...string) (*RequestQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return rq, nil
	}
	if err := rq.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return rq, nil
}

func (rq *RequestQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(request.Columns))
		selectedFields = []string{request.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: rq.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			rq.withUser = query
			if _, ok := fieldSeen[request.FieldUserID]; !ok {
				selectedFields = append(selectedFields, request.FieldUserID)
				fieldSeen[request.FieldUserID] = struct{}{}
			}

		case "apiKey":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&APIKeyClient{config: rq.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, apikeyImplementors)...); err != nil {
				return err
			}
			rq.withAPIKey = query
			if _, ok := fieldSeen[request.FieldAPIKeyID]; !ok {
				selectedFields = append(selectedFields, request.FieldAPIKeyID)
				fieldSeen[request.FieldAPIKeyID] = struct{}{}
			}

		case "executions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestExecutionClient{config: rq.config}).Query()
			)
			args := newRequestExecutionPaginateArgs(fieldArgs(ctx, new(RequestExecutionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestExecutionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					rq.loadTotal = append(rq.loadTotal, func(ctx context.Context, nodes []*Request) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"request_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(request.ExecutionsColumn), ids...))
						})
						if err := query.GroupBy(request.ExecutionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					rq.loadTotal = append(rq.loadTotal, func(_ context.Context, nodes []*Request) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Executions)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestexecutionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(request.ExecutionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			rq.WithNamedExecutions(alias, func(wq *RequestExecutionQuery) {
				*wq = *query
			})

		case "channel":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ChannelClient{config: rq.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, channelImplementors)...); err != nil {
				return err
			}
			rq.withChannel = query
			if _, ok := fieldSeen[request.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, request.FieldChannelID)
				fieldSeen[request.FieldChannelID] = struct{}{}
			}

		case "usageLogs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UsageLogClient{config: rq.config}).Query()
			)
			args := newUsageLogPaginateArgs(fieldArgs(ctx, new(UsageLogWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUsageLogPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					rq.loadTotal = append(rq.loadTotal, func(ctx context.Context, nodes []*Request) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"request_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(request.UsageLogsColumn), ids...))
						})
						if err := query.GroupBy(request.UsageLogsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					rq.loadTotal = append(rq.loadTotal, func(_ context.Context, nodes []*Request) error {
						for i := range nodes {
							n := len(nodes[i].Edges.UsageLogs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, usagelogImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(request.UsageLogsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			rq.WithNamedUsageLogs(alias, func(wq *UsageLogQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[request.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, request.FieldCreatedAt)
				fieldSeen[request.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[request.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, request.FieldUpdatedAt)
				fieldSeen[request.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[request.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, request.FieldDeletedAt)
				fieldSeen[request.FieldDeletedAt] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[request.FieldUserID]; !ok {
				selectedFields = append(selectedFields, request.FieldUserID)
				fieldSeen[request.FieldUserID] = struct{}{}
			}
		case "apiKeyID":
			if _, ok := fieldSeen[request.FieldAPIKeyID]; !ok {
				selectedFields = append(selectedFields, request.FieldAPIKeyID)
				fieldSeen[request.FieldAPIKeyID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[request.FieldSource]; !ok {
				selectedFields = append(selectedFields, request.FieldSource)
				fieldSeen[request.FieldSource] = struct{}{}
			}
		case "modelID":
			if _, ok := fieldSeen[request.FieldModelID]; !ok {
				selectedFields = append(selectedFields, request.FieldModelID)
				fieldSeen[request.FieldModelID] = struct{}{}
			}
		case "format":
			if _, ok := fieldSeen[request.FieldFormat]; !ok {
				selectedFields = append(selectedFields, request.FieldFormat)
				fieldSeen[request.FieldFormat] = struct{}{}
			}
		case "requestBody":
			if _, ok := fieldSeen[request.FieldRequestBody]; !ok {
				selectedFields = append(selectedFields, request.FieldRequestBody)
				fieldSeen[request.FieldRequestBody] = struct{}{}
			}
		case "responseBody":
			if _, ok := fieldSeen[request.FieldResponseBody]; !ok {
				selectedFields = append(selectedFields, request.FieldResponseBody)
				fieldSeen[request.FieldResponseBody] = struct{}{}
			}
		case "responseChunks":
			if _, ok := fieldSeen[request.FieldResponseChunks]; !ok {
				selectedFields = append(selectedFields, request.FieldResponseChunks)
				fieldSeen[request.FieldResponseChunks] = struct{}{}
			}
		case "channelID":
			if _, ok := fieldSeen[request.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, request.FieldChannelID)
				fieldSeen[request.FieldChannelID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[request.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, request.FieldExternalID)
				fieldSeen[request.FieldExternalID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[request.FieldStatus]; !ok {
				selectedFields = append(selectedFields, request.FieldStatus)
				fieldSeen[request.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		rq.Select(selectedFields...)
	}
	return nil
}

type requestPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RequestPaginateOption
}

func newRequestPaginateArgs(rv map[string]any) *requestPaginateArgs {
	args := &requestPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &RequestOrder{Field: &RequestOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithRequestOrder(order))
			}
		case *RequestOrder:
			if v != nil {
				args.opts = append(args.opts, WithRequestOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*RequestWhereInput); ok {
		args.opts = append(args.opts, WithRequestFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (req *RequestExecutionQuery) CollectFields(ctx context.Context, satisfies ...string) (*RequestExecutionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return req, nil
	}
	if err := req.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return req, nil
}

func (req *RequestExecutionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(requestexecution.Columns))
		selectedFields = []string{requestexecution.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "request":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: req.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
				return err
			}
			req.withRequest = query
			if _, ok := fieldSeen[requestexecution.FieldRequestID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldRequestID)
				fieldSeen[requestexecution.FieldRequestID] = struct{}{}
			}

		case "channel":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ChannelClient{config: req.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, channelImplementors)...); err != nil {
				return err
			}
			req.withChannel = query
			if _, ok := fieldSeen[requestexecution.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldChannelID)
				fieldSeen[requestexecution.FieldChannelID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[requestexecution.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldCreatedAt)
				fieldSeen[requestexecution.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[requestexecution.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldUpdatedAt)
				fieldSeen[requestexecution.FieldUpdatedAt] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[requestexecution.FieldUserID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldUserID)
				fieldSeen[requestexecution.FieldUserID] = struct{}{}
			}
		case "requestID":
			if _, ok := fieldSeen[requestexecution.FieldRequestID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldRequestID)
				fieldSeen[requestexecution.FieldRequestID] = struct{}{}
			}
		case "channelID":
			if _, ok := fieldSeen[requestexecution.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldChannelID)
				fieldSeen[requestexecution.FieldChannelID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[requestexecution.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldExternalID)
				fieldSeen[requestexecution.FieldExternalID] = struct{}{}
			}
		case "modelID":
			if _, ok := fieldSeen[requestexecution.FieldModelID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldModelID)
				fieldSeen[requestexecution.FieldModelID] = struct{}{}
			}
		case "format":
			if _, ok := fieldSeen[requestexecution.FieldFormat]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldFormat)
				fieldSeen[requestexecution.FieldFormat] = struct{}{}
			}
		case "requestBody":
			if _, ok := fieldSeen[requestexecution.FieldRequestBody]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldRequestBody)
				fieldSeen[requestexecution.FieldRequestBody] = struct{}{}
			}
		case "responseBody":
			if _, ok := fieldSeen[requestexecution.FieldResponseBody]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldResponseBody)
				fieldSeen[requestexecution.FieldResponseBody] = struct{}{}
			}
		case "responseChunks":
			if _, ok := fieldSeen[requestexecution.FieldResponseChunks]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldResponseChunks)
				fieldSeen[requestexecution.FieldResponseChunks] = struct{}{}
			}
		case "errorMessage":
			if _, ok := fieldSeen[requestexecution.FieldErrorMessage]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldErrorMessage)
				fieldSeen[requestexecution.FieldErrorMessage] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[requestexecution.FieldStatus]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldStatus)
				fieldSeen[requestexecution.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		req.Select(selectedFields...)
	}
	return nil
}

type requestexecutionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RequestExecutionPaginateOption
}

func newRequestExecutionPaginateArgs(rv map[string]any) *requestexecutionPaginateArgs {
	args := &requestexecutionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &RequestExecutionOrder{Field: &RequestExecutionOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithRequestExecutionOrder(order))
			}
		case *RequestExecutionOrder:
			if v != nil {
				args.opts = append(args.opts, WithRequestExecutionOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*RequestExecutionWhereInput); ok {
		args.opts = append(args.opts, WithRequestExecutionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (rq *RoleQuery) CollectFields(ctx context.Context, satisfies ...string) (*RoleQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return rq, nil
	}
	if err := rq.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return rq, nil
}

func (rq *RoleQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(role.Columns))
		selectedFields = []string{role.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: rq.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					rq.loadTotal = append(rq.loadTotal, func(ctx context.Context, nodes []*Role) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"role_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(role.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(role.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(role.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(role.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(role.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					rq.loadTotal = append(rq.loadTotal, func(_ context.Context, nodes []*Role) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(role.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			rq.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[role.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, role.FieldCreatedAt)
				fieldSeen[role.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[role.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, role.FieldUpdatedAt)
				fieldSeen[role.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[role.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, role.FieldDeletedAt)
				fieldSeen[role.FieldDeletedAt] = struct{}{}
			}
		case "code":
			if _, ok := fieldSeen[role.FieldCode]; !ok {
				selectedFields = append(selectedFields, role.FieldCode)
				fieldSeen[role.FieldCode] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[role.FieldName]; !ok {
				selectedFields = append(selectedFields, role.FieldName)
				fieldSeen[role.FieldName] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[role.FieldScopes]; !ok {
				selectedFields = append(selectedFields, role.FieldScopes)
				fieldSeen[role.FieldScopes] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		rq.Select(selectedFields...)
	}
	return nil
}

type rolePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RolePaginateOption
}

func newRolePaginateArgs(rv map[string]any) *rolePaginateArgs {
	args := &rolePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &RoleOrder{Field: &RoleOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithRoleOrder(order))
			}
		case *RoleOrder:
			if v != nil {
				args.opts = append(args.opts, WithRoleOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*RoleWhereInput); ok {
		args.opts = append(args.opts, WithRoleFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (sq *SystemQuery) CollectFields(ctx context.Context, satisfies ...string) (*SystemQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return sq, nil
	}
	if err := sq.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return sq, nil
}

func (sq *SystemQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(system.Columns))
		selectedFields = []string{system.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "createdAt":
			if _, ok := fieldSeen[system.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, system.FieldCreatedAt)
				fieldSeen[system.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[system.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, system.FieldUpdatedAt)
				fieldSeen[system.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[system.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, system.FieldDeletedAt)
				fieldSeen[system.FieldDeletedAt] = struct{}{}
			}
		case "key":
			if _, ok := fieldSeen[system.FieldKey]; !ok {
				selectedFields = append(selectedFields, system.FieldKey)
				fieldSeen[system.FieldKey] = struct{}{}
			}
		case "value":
			if _, ok := fieldSeen[system.FieldValue]; !ok {
				selectedFields = append(selectedFields, system.FieldValue)
				fieldSeen[system.FieldValue] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		sq.Select(selectedFields...)
	}
	return nil
}

type systemPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SystemPaginateOption
}

func newSystemPaginateArgs(rv map[string]any) *systemPaginateArgs {
	args := &systemPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &SystemOrder{Field: &SystemOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithSystemOrder(order))
			}
		case *SystemOrder:
			if v != nil {
				args.opts = append(args.opts, WithSystemOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*SystemWhereInput); ok {
		args.opts = append(args.opts, WithSystemFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (ulq *UsageLogQuery) CollectFields(ctx context.Context, satisfies ...string) (*UsageLogQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return ulq, nil
	}
	if err := ulq.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return ulq, nil
}

func (ulq *UsageLogQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(usagelog.Columns))
		selectedFields = []string{usagelog.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: ulq.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			ulq.withUser = query
			if _, ok := fieldSeen[usagelog.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldUserID)
				fieldSeen[usagelog.FieldUserID] = struct{}{}
			}

		case "request":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: ulq.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
				return err
			}
			ulq.withRequest = query
			if _, ok := fieldSeen[usagelog.FieldRequestID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldRequestID)
				fieldSeen[usagelog.FieldRequestID] = struct{}{}
			}

		case "channel":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ChannelClient{config: ulq.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, channelImplementors)...); err != nil {
				return err
			}
			ulq.withChannel = query
			if _, ok := fieldSeen[usagelog.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldChannelID)
				fieldSeen[usagelog.FieldChannelID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[usagelog.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCreatedAt)
				fieldSeen[usagelog.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[usagelog.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldUpdatedAt)
				fieldSeen[usagelog.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[usagelog.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldDeletedAt)
				fieldSeen[usagelog.FieldDeletedAt] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[usagelog.FieldUserID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldUserID)
				fieldSeen[usagelog.FieldUserID] = struct{}{}
			}
		case "requestID":
			if _, ok := fieldSeen[usagelog.FieldRequestID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldRequestID)
				fieldSeen[usagelog.FieldRequestID] = struct{}{}
			}
		case "channelID":
			if _, ok := fieldSeen[usagelog.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldChannelID)
				fieldSeen[usagelog.FieldChannelID] = struct{}{}
			}
		case "modelID":
			if _, ok := fieldSeen[usagelog.FieldModelID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldModelID)
				fieldSeen[usagelog.FieldModelID] = struct{}{}
			}
		case "promptTokens":
			if _, ok := fieldSeen[usagelog.FieldPromptTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldPromptTokens)
				fieldSeen[usagelog.FieldPromptTokens] = struct{}{}
			}
		case "completionTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionTokens)
				fieldSeen[usagelog.FieldCompletionTokens] = struct{}{}
			}
		case "totalTokens":
			if _, ok := fieldSeen[usagelog.FieldTotalTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldTotalTokens)
				fieldSeen[usagelog.FieldTotalTokens] = struct{}{}
			}
		case "promptAudioTokens":
			if _, ok := fieldSeen[usagelog.FieldPromptAudioTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldPromptAudioTokens)
				fieldSeen[usagelog.FieldPromptAudioTokens] = struct{}{}
			}
		case "promptCachedTokens":
			if _, ok := fieldSeen[usagelog.FieldPromptCachedTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldPromptCachedTokens)
				fieldSeen[usagelog.FieldPromptCachedTokens] = struct{}{}
			}
		case "completionAudioTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionAudioTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionAudioTokens)
				fieldSeen[usagelog.FieldCompletionAudioTokens] = struct{}{}
			}
		case "completionReasoningTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionReasoningTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionReasoningTokens)
				fieldSeen[usagelog.FieldCompletionReasoningTokens] = struct{}{}
			}
		case "completionAcceptedPredictionTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionAcceptedPredictionTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionAcceptedPredictionTokens)
				fieldSeen[usagelog.FieldCompletionAcceptedPredictionTokens] = struct{}{}
			}
		case "completionRejectedPredictionTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionRejectedPredictionTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionRejectedPredictionTokens)
				fieldSeen[usagelog.FieldCompletionRejectedPredictionTokens] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[usagelog.FieldSource]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldSource)
				fieldSeen[usagelog.FieldSource] = struct{}{}
			}
		case "format":
			if _, ok := fieldSeen[usagelog.FieldFormat]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldFormat)
				fieldSeen[usagelog.FieldFormat] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		ulq.Select(selectedFields...)
	}
	return nil
}

type usagelogPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UsageLogPaginateOption
}

func newUsageLogPaginateArgs(rv map[string]any) *usagelogPaginateArgs {
	args := &usagelogPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UsageLogOrder{Field: &UsageLogOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUsageLogOrder(order))
			}
		case *UsageLogOrder:
			if v != nil {
				args.opts = append(args.opts, WithUsageLogOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UsageLogWhereInput); ok {
		args.opts = append(args.opts, WithUsageLogFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (uq *UserQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return uq, nil
	}
	if err := uq.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return uq, nil
}

func (uq *UserQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(user.Columns))
		selectedFields = []string{user.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "requests":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: uq.config}).Query()
			)
			args := newRequestPaginateArgs(fieldArgs(ctx, new(RequestWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					uq.loadTotal = append(uq.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.RequestsColumn), ids...))
						})
						if err := query.GroupBy(user.RequestsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					uq.loadTotal = append(uq.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Requests)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.RequestsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			uq.WithNamedRequests(alias, func(wq *RequestQuery) {
				*wq = *query
			})

		case "apiKeys":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&APIKeyClient{config: uq.config}).Query()
			)
			args := newAPIKeyPaginateArgs(fieldArgs(ctx, new(APIKeyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAPIKeyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					uq.loadTotal = append(uq.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.APIKeysColumn), ids...))
						})
						if err := query.GroupBy(user.APIKeysColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					uq.loadTotal = append(uq.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.APIKeys)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, apikeyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.APIKeysColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			uq.WithNamedAPIKeys(alias, func(wq *APIKeyQuery) {
				*wq = *query
			})

		case "roles":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RoleClient{config: uq.config}).Query()
			)
			args := newRolePaginateArgs(fieldArgs(ctx, new(RoleWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRolePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					uq.loadTotal = append(uq.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.RolesTable)
							s.Join(joinT).On(s.C(role.FieldID), joinT.C(user.RolesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.RolesPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.RolesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.RolesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					uq.loadTotal = append(uq.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Roles)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, roleImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.RolesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			uq.WithNamedRoles(alias, func(wq *RoleQuery) {
				*wq = *query
			})

		case "usageLogs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UsageLogClient{config: uq.config}).Query()
			)
			args := newUsageLogPaginateArgs(fieldArgs(ctx, new(UsageLogWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUsageLogPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					uq.loadTotal = append(uq.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.UsageLogsColumn), ids...))
						})
						if err := query.GroupBy(user.UsageLogsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					uq.loadTotal = append(uq.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.UsageLogs)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, usagelogImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.UsageLogsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			uq.WithNamedUsageLogs(alias, func(wq *UsageLogQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[user.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldCreatedAt)
				fieldSeen[user.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[user.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldUpdatedAt)
				fieldSeen[user.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[user.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldDeletedAt)
				fieldSeen[user.FieldDeletedAt] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[user.FieldEmail]; !ok {
				selectedFields = append(selectedFields, user.FieldEmail)
				fieldSeen[user.FieldEmail] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[user.FieldStatus]; !ok {
				selectedFields = append(selectedFields, user.FieldStatus)
				fieldSeen[user.FieldStatus] = struct{}{}
			}
		case "preferLanguage":
			if _, ok := fieldSeen[user.FieldPreferLanguage]; !ok {
				selectedFields = append(selectedFields, user.FieldPreferLanguage)
				fieldSeen[user.FieldPreferLanguage] = struct{}{}
			}
		case "firstName":
			if _, ok := fieldSeen[user.FieldFirstName]; !ok {
				selectedFields = append(selectedFields, user.FieldFirstName)
				fieldSeen[user.FieldFirstName] = struct{}{}
			}
		case "lastName":
			if _, ok := fieldSeen[user.FieldLastName]; !ok {
				selectedFields = append(selectedFields, user.FieldLastName)
				fieldSeen[user.FieldLastName] = struct{}{}
			}
		case "avatar":
			if _, ok := fieldSeen[user.FieldAvatar]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatar)
				fieldSeen[user.FieldAvatar] = struct{}{}
			}
		case "isOwner":
			if _, ok := fieldSeen[user.FieldIsOwner]; !ok {
				selectedFields = append(selectedFields, user.FieldIsOwner)
				fieldSeen[user.FieldIsOwner] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[user.FieldScopes]; !ok {
				selectedFields = append(selectedFields, user.FieldScopes)
				fieldSeen[user.FieldScopes] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		uq.Select(selectedFields...)
	}
	return nil
}

type userPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserPaginateOption
}

func newUserPaginateArgs(rv map[string]any) *userPaginateArgs {
	args := &userPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UserOrder{Field: &UserOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUserOrder(order))
			}
		case *UserOrder:
			if v != nil {
				args.opts = append(args.opts, WithUserOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UserWhereInput); ok {
		args.opts = append(args.opts, WithUserFilter(v.Filter))
	}
	return args
}

const (
	afterField     = "after"
	firstField     = "first"
	beforeField    = "before"
	lastField      = "last"
	orderByField   = "orderBy"
	directionField = "direction"
	fieldField     = "field"
	whereField     = "where"
)

func fieldArgs(ctx context.Context, whereInput any, path ...string) map[string]any {
	field := collectedField(ctx, path...)
	if field == nil || field.Arguments == nil {
		return nil
	}
	oc := graphql.GetOperationContext(ctx)
	args := field.ArgumentMap(oc.Variables)
	return unmarshalArgs(ctx, whereInput, args)
}

// unmarshalArgs allows extracting the field arguments from their raw representation.
func unmarshalArgs(ctx context.Context, whereInput any, args map[string]any) map[string]any {
	for _, k := range []string{firstField, lastField} {
		v, ok := args[k]
		if !ok || v == nil {
			continue
		}
		i, err := graphql.UnmarshalInt(v)
		if err == nil {
			args[k] = &i
		}
	}
	for _, k := range []string{beforeField, afterField} {
		v, ok := args[k]
		if !ok {
			continue
		}
		c := &Cursor{}
		if c.UnmarshalGQL(v) == nil {
			args[k] = c
		}
	}
	if v, ok := args[whereField]; ok && whereInput != nil {
		if err := graphql.UnmarshalInputFromContext(ctx, v, whereInput); err == nil {
			args[whereField] = whereInput
		}
	}

	return args
}

// mayAddCondition appends another type condition to the satisfies list
// if it does not exist in the list.
func mayAddCondition(satisfies []string, typeCond []string) []string {
Cond:
	for _, c := range typeCond {
		for _, s := range satisfies {
			if c == s {
				continue Cond
			}
		}
		satisfies = append(satisfies, c)
	}
	return satisfies
}
